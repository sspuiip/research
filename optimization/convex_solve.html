<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>2. 优化问题求解(1) &mdash; MLBOOK 1.0 文档</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
        <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="../_static/mathjax/tex-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="3. 优化问题求解(2)" href="convex_neq_solve.html" />
    <link rel="prev" title="1. 凸优化问题" href="convex_prob.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> MLBOOK
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">矩阵分析</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../matrix/base.html">1. 矩阵性能指标</a></li>
<li class="toctree-l1"><a class="reference internal" href="../matrix/matrixoper.html">2. 矩阵运算</a></li>
<li class="toctree-l1"><a class="reference internal" href="../matrix/vectorspace.html">3. 向量空间</a></li>
<li class="toctree-l1"><a class="reference internal" href="../matrix/matrixdiff.html">4. 矩阵微分</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">最优化</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="convex_prob.html">1. 凸优化问题</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">2. 优化问题求解(1)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">2.1. 下降法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">2.1.1. 最速下降法</a></li>
<li class="toctree-l3"><a class="reference internal" href="#newton">2.1.2. Newton法</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id4">2.2. 梯度投影法</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id5">2.3. 共轭梯度下降法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#mathbf-a">2.3.1. <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">2.3.2. 共轭梯度法</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">2.3.3. 案例</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">2.3.4. 一般函数的共轭梯度法</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id9">2.4. Newton方法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="convex_neq_solve.html">3. 优化问题求解(2)</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MLBOOK</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li><span class="section-number">2. </span>优化问题求解(1)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/optimization/convex_solve.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1><span class="section-number">2. </span>优化问题求解(1)<a class="headerlink" href="#id1" title="永久链接至标题"></a></h1>
<section id="id2">
<h2><span class="section-number">2.1. </span>下降法<a class="headerlink" href="#id2" title="永久链接至标题"></a></h2>
<p>  基本思想：利用优化序列</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_{k+1}=\mathbf{x}_k+\mu_k\Delta\mathbf{x}_k,\quad k=1,2,\cdots\tag{1}
\]</div>
<p>寻找最优点<span class="math notranslate nohighlight">\(\mathbf{x}_{opt}\)</span>。<span class="math notranslate nohighlight">\(\mu_k\)</span>为第<span class="math notranslate nohighlight">\(k\)</span>次迭代的步长，<span class="math notranslate nohighlight">\(\Delta\mathbf{x}_k\)</span>为搜索方向其值为一个向量<span class="math notranslate nohighlight">\(\Delta\mathbf{x}\in\mathbb{R}^n\)</span>。最小化算法要求迭代过程中目标函数是下降的，</p>
<div class="math notranslate nohighlight">
\[
f(\mathbf{x}_{k+1})&lt;f(\mathbf{x}_k)
\]</div>
<p>所以该方法称为<font color='red'><strong>下降法</strong></font>。</p>
<section id="id3">
<h3><span class="section-number">2.1.1. </span>最速下降法<a class="headerlink" href="#id3" title="永久链接至标题"></a></h3>
<p>  由Taylor公式可知，</p>
<div class="math notranslate nohighlight">
\[
f(\mathbf{x}_{k+1})- f(\mathbf{x}_k)\approx\nabla f(\mathbf{x}_k)^\top\Delta\mathbf{x}_k\tag{2}
\]</div>
<p>显然，当<span class="math notranslate nohighlight">\(0\le\theta\le \pi/2\)</span>, 令</p>
<div class="math notranslate nohighlight">
\[
\Delta\mathbf{x}_k=-\nabla f(\mathbf{x}_k)\cos\theta\tag{3}
\]</div>
<p>必然有，<span class="math notranslate nohighlight">\(f(\mathbf{x}_{k+1})&lt;f(\mathbf{x}_k)\)</span>成立。</p>
<ul class="simple">
<li><p>取<span class="math notranslate nohighlight">\(\theta=0\)</span>，则<span class="math notranslate nohighlight">\(\Delta\mathbf{x}_k=-\nabla f(\mathbf{x}_k)\)</span>，即搜索方向为负梯度方向，步长为<span class="math notranslate nohighlight">\(\lVert \nabla f(\mathbf{x}_k)\rVert_2^2\)</span>，故下降方向具有最大的下降步伐。与之对应的下降法称为<font color='red'><strong>最速下降法</strong></font>。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_{k+1}=\mathbf{x}_k+\mu_k\nabla f(\mathbf{x}_k)\tag{4}
\]</div>
</section>
<section id="newton">
<h3><span class="section-number">2.1.2. </span>Newton法<a class="headerlink" href="#newton" title="永久链接至标题"></a></h3>
<p>  Taylor公式展开至二阶有，</p>
<div class="math notranslate nohighlight">
\[
f(\mathbf{x}_{k+1})\approx f(\mathbf{x}_k)+\nabla f(\mathbf{x}_k)^\top\Delta\mathbf{x}_k+\frac12(\Delta\mathbf{x}_k)^\top\nabla^2f(\mathbf{x}_k)(\Delta\mathbf{x}_k)\tag{5}
\]</div>
<p>显然最优化下降方向应该是让二阶展开式最得最小值的方向，即</p>
<div class="math notranslate nohighlight">
\[
\min\limits_{\Delta\mathbf{x}_k}\left[f(\mathbf{x}_k)+\nabla f(\mathbf{x}_k)^\top\Delta\mathbf{x}_k+\frac12(\Delta\mathbf{x}_k)^\top\nabla^2f(\mathbf{x}_k)(\Delta\mathbf{x}_k)\right]\tag{6}
\]</div>
<p>对二阶展开式求导，可知，</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial f(\mathbf{x}_k+\Delta\mathbf{x}_k)}{\partial \Delta\mathbf{x}_k}=\nabla f(\mathbf{x}_k)+\nabla^2f(\mathbf{x}_k)\Delta\mathbf{x}_k=0\tag{7}
\]</div>
<p>则有最优搜索方向，</p>
<div class="math notranslate nohighlight">
\[
\Delta\mathbf{x}_k=-\nabla^2f(\mathbf{x}_k)\nabla f(\mathbf{x}_k)\tag{8}
\]</div>
<p>该下降方向也称之为Newton步或Newton下降方向，记为<span class="math notranslate nohighlight">\(\Delta\mathbf{x}_{nt}\)</span>，相应的方法称为<font color='red'><strong>Newton法</strong></font>。</p>
</section>
</section>
<section id="id4">
<h2><span class="section-number">2.2. </span>梯度投影法<a class="headerlink" href="#id4" title="永久链接至标题"></a></h2>
<p>  梯度下降法中变元是无约束的。若有约束<span class="math notranslate nohighlight">\(\mathbf{x}\in\mathcal{C}\)</span>，则梯度下降法中的更新公式应用投影代替，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_{k+1}=\mathcal{P}_\mathcal{C}(\mathbf{x}_k-\mu_k\nabla f(\mathbf{x}_k))\tag{9}
\]</div>
<p>这一算法称为梯度投影法，也称为投影梯度法。投影算子<span class="math notranslate nohighlight">\(\mathcal{P}_\mathcal{C}(\mathbf{y})\)</span>定义为</p>
<div class="math notranslate nohighlight">
\[
\mathcal{P}_\mathcal{C}(\mathbf{y})=\arg\min\limits_{\mathbf{x}\in\mathcal{C}}\frac12\lVert \mathbf{x}-\mathbf{y}\rVert_2^2\tag{10}
\]</div>
<p>  <strong>例</strong>. 到超平面<span class="math notranslate nohighlight">\(\mathcal{C}=\{\mathbf{x}|\mathbf{a}^\top\mathbf{x}=b\}\)</span>的投影，</p>
<div class="math notranslate nohighlight">
\[
\mathcal{P}_\mathcal{C}(\mathbf{x})=\mathbf{x}+\frac{b-\mathbf{a}^\top\mathbf{x}}{\lVert\mathbf{a}\rVert_2^2}\mathbf{a}
\]</div>
<p>  求解过程：投影问题为如下优化问题，</p>
<div class="math notranslate nohighlight">
\[
\mathcal{P}_\mathcal{C}(\mathbf{x})=\arg\min\limits_{\mathbf{z}\in\mathcal{C}}\frac12\lVert \mathbf{x}-\mathbf{z}\rVert_2^2 \quad s.t.\quad \mathbf{a}^\top\mathbf{x}-b=0
\]</div>
<p>则Lagrangian函数为，</p>
<div class="math notranslate nohighlight">
\[
L(\mathbf{x},\lambda)=\frac12\lVert \mathbf{x}-\mathbf{z}\rVert_2^2  +\lambda( \mathbf{a}^\top\mathbf{z}-b)
\]</div>
<p>对Lagrangian函数求偏导并令其等于0，可得</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\frac{\partial L}{\partial \mathbf{z}}&amp;=\mathbf{z}-\mathbf{x}+\lambda \mathbf{a}=0\\
\frac{\partial L}{\partial \lambda}&amp;=\mathbf{a}^\top\mathbf{z}-b=0\\
\end{split}
\end{split}\]</div>
<p>解上述方程组，将<span class="math notranslate nohighlight">\(\mathbf{z}=\mathbf{x}-\lambda \mathbf{a}\)</span>代入<span class="math notranslate nohighlight">\(\mathbf{a}^\top\mathbf{z}-b=0\)</span>，可得，</p>
<div class="math notranslate nohighlight">
\[
\lambda = \frac{\mathbf{a}^\top\mathbf{x}-b}{\mathbf{a}^\top\mathbf{a}}
\]</div>
<p>再将<span class="math notranslate nohighlight">\(\lambda\)</span>代入<span class="math notranslate nohighlight">\(\mathbf{z}-\mathbf{x}+\lambda \mathbf{a}=0\)</span>，可得</p>
<div class="math notranslate nohighlight">
\[
\mathbf{z}=\mathbf{x}+\frac{b-\mathbf{a}^\top\mathbf{x}}{\mathbf{a}^\top\mathbf{a}}\mathbf{a}
\]</div>
</section>
<section id="id5">
<h2><span class="section-number">2.3. </span>共轭梯度下降法<a class="headerlink" href="#id5" title="永久链接至标题"></a></h2>
<p>  最速下降法的存在一个问题就是收敛速度过慢，因为已迭代的<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>会来回振荡，从而导致收敛太慢。</p>
<p>  Newton法虽然收收敛较快，但仍需要计算Hessian矩阵的逆，因此计算代价太高。</p>
<p>  为了加速最速下降法的收敛速度和避免Newton法的Hessian逆矩阵计算，提出了共轭梯度下降法。</p>
<p><img alt="alt Conjugate Gradient Descent" src="../_images/conj_desc.png" /></p>
<p>  与前面两种下降方法类似，共轭梯度下降也是通过迭代来寻找最优点，即</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_{k+1}=\mathbf{x}_k+\alpha_k\mathbf{d}_k\tag{11}
\]</div>
<p>  <strong>不同之处</strong>在于，每次迭代的下降方向向量<span class="math notranslate nohighlight">\(\mathbf{d}_i\)</span>与其它任何一次方向向量<span class="math notranslate nohighlight">\(\mathbf{d}_j,j\neq i\)</span>都是<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭的；此外，<span class="math notranslate nohighlight">\(\alpha_i\)</span>是<span class="math notranslate nohighlight">\(\min\limits_{\alpha}f(\mathbf{x}_{i-1}+\alpha\mathbf{d}_i)\)</span>的最优值。</p>
<p>  为了简要描述共轭的思想，以上图为例，坐标轴可以指定为搜索方向。第一步沿着水平方向到达<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>的<span class="math notranslate nohighlight">\(x_1\)</span>分量部分。第二步没着垂直方向到达<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>的<span class="math notranslate nohighlight">\(x_2\)</span>分量部分，然后结束搜索过程就可以确定<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>的值。如果定义<span class="math notranslate nohighlight">\(\mathbf{e}_i=\mathbf{x}^*-\mathbf{x}_i\)</span>，则可以发现,</p>
<div class="math notranslate nohighlight">
\[
\mathbf{d}_i^\top\mathbf{e}_{i+1}=0
\]</div>
<p>共轭梯度下降法源于二次规划问题的求解，即</p>
<div class="math notranslate nohighlight">
\[
\min\limits_{\mathbf{x}}\quad \frac12\mathbf{x}^\top\mathbf{A}\mathbf{x}-\mathbf{b}^\top\mathbf{x}\quad(\mathbf{A}\succeq0)
\]</div>
<p>其梯度为<span class="math notranslate nohighlight">\(\nabla f(\mathbf{x})=\mathbf{Ax}-b\triangleq r(\mathbf{x})\)</span>，则求解最优值<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>等价于求解方程组<span class="math notranslate nohighlight">\(\mathbf{Ax}-\mathbf{b}=\mathbf{0}\)</span>。如果<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>是一个对称正定矩阵，那么必然可以构建一个<span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>空间的一个基，显然基的每个向量与其它基向量是共轭的。</p>
<p>  下降方向能不能和这些基向量建立联系呢？答案是肯定的。易知，最优解<span class="math notranslate nohighlight">\(\mathbf{x}^\top\)</span>可以表示为</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}^*=\sum_{i=0}^{n-1}\alpha_i\mathbf{d}_i\tag{12}
\]</div>
<p>如果<span class="math notranslate nohighlight">\(\alpha_i,\mathbf{d}_i\)</span>都已知，则<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>可通过上式确定。</p>
<section id="mathbf-a">
<h3><span class="section-number">2.3.1. </span><span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭<a class="headerlink" href="#mathbf-a" title="永久链接至标题"></a></h3>
<p>  <strong>定义1</strong>.假设<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>是一个对称正定矩阵，那么称向量<span class="math notranslate nohighlight">\(\mathbf{d}_i,\mathbf{d}_j\)</span>是<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭的，如果满足，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{d}_i^\top\mathbf{A}\mathbf{d}_j=0,\quad i\neq j.
\]</div>
<p>  <strong>定理1</strong>. 两两向量相互<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭的向量集<span class="math notranslate nohighlight">\(\{\mathbf{d}_0,...,\mathbf{d}_{n-1}\}\)</span>构成了一个<span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>空间的一个基，即<span class="math notranslate nohighlight">\(\{\mathbf{d}_0,...,\mathbf{d}_{n-1}\}\)</span>线性无关。</p>
<p>  有了<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭就可以来确定式(12)的各参数值了。</p>
<ul class="simple">
<li><p>首先求<span class="math notranslate nohighlight">\(\alpha_i\)</span>的表达式。</p></li>
</ul>
<p>  对式(12)左右同时乘上<span class="math notranslate nohighlight">\(\mathbf{d}_k^\top\mathbf{A}\)</span>，利用<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭性可得</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\mathbf{d}_k^\top\mathbf{A}\mathbf{x}^*&amp;=\sum_{i=0}^{n-1}\alpha_i\mathbf{d}_k^\top\mathbf{Ad}_i\\
\Rightarrow\alpha_k&amp;=\frac{\mathbf{d}_k^\top\mathbf{b}}{\mathbf{d}_k^\top\mathbf{Ad}_k}
\end{split}
\end{split}\]</div>
<p>可以看出，<span class="math notranslate nohighlight">\(\alpha_k\)</span>只与搜索方向<span class="math notranslate nohighlight">\(\mathbf{d}_k\)</span>有关，因此，只需要迭代<span class="math notranslate nohighlight">\(n\)</span>次就可以计算出<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>，即</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}^*=\sum_{i=0}^{n-1}\frac{\mathbf{d}_i^\top\mathbf{b}}{\mathbf{d}_i^\top\mathbf{Ad}_i}\mathbf{d}_i
\]</div>
<p>  为了演示上述过程在<span class="math notranslate nohighlight">\(n\)</span>步计算出<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>，引入如下定理。</p>
<p>  <strong>定理2</strong>. 假设<span class="math notranslate nohighlight">\(\{\mathbf{d}_0,...,\mathbf{d}_{n-1}\}\)</span>是<span class="math notranslate nohighlight">\(n\)</span>个<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭的向量，<span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>是初使点，令</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\mathbf{x}_{k+1}&amp;=\mathbf{x}_k+\alpha_k\mathbf{d}_k\\
\mathbf{g}_k&amp;=\mathbf{b}-\mathbf{Ax}_k\\
\alpha_k&amp;=\frac{\mathbf{g}_k^\top\mathbf{d}_k}{\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_k}=\frac{(\mathbf{b}-\mathbf{Ax})_k^\top\mathbf{d}_k}{\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_k}
\end{split}
\end{split}\]</div>
<p>则迭代<span class="math notranslate nohighlight">\(n\)</span>次后，<span class="math notranslate nohighlight">\(\mathbf{x}_n=\mathbf{x}^*\)</span>。</p>
<p>  <strong>证明</strong>. 从起始点<span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>到<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>的误差<span class="math notranslate nohighlight">\(\mathbf{e}_0\)</span>为，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}^*-\mathbf{x}_0=\alpha_0\mathbf{d}_0+\alpha_1\mathbf{d}_1+\cdots+\alpha_{n-1}\mathbf{d}_{n-1}
\]</div>
<p>从起始点<span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>到<span class="math notranslate nohighlight">\(\mathbf{x}_k\)</span>可以表示为，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_k-\mathbf{x}_0=\alpha_0\mathbf{d}_0+\alpha_1\mathbf{d}_1+\cdots+\alpha_{k-1}\mathbf{d}_{k-1}
\]</div>
<p><span class="math notranslate nohighlight">\(\mathbf{x}_k\)</span>的残差为</p>
<div class="math notranslate nohighlight">
\[
\mathbf{g}_k=\mathbf{b}-\mathbf{Ax}_k=\mathbf{A}(\mathbf{x}^*-\mathbf{x}_k)
\]</div>
<p>因此可得<span class="math notranslate nohighlight">\(\alpha_k\)</span>如下，</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_0)&amp;=\mathbf{d}_k^\top\mathbf{A}( \alpha_0\mathbf{d}_0+\alpha_1\mathbf{d}_1+\cdots+\alpha_{n-1}\mathbf{d}_{n-1})=\alpha_k\mathbf{d}_k^\top\mathbf{Ad}_k\\
\Rightarrow\alpha_k&amp;=\frac{\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_0)}{\mathbf{d}_k^\top\mathbf{Ad}_k}
\end{split}
\end{split}\]</div>
<p>但仍然需要提前知道<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>才能计算<span class="math notranslate nohighlight">\(\alpha_k\)</span>。下面分析一下分子项。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_0)&amp;=\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_k+\mathbf{x}_k-\mathbf{x}_0)\\
&amp;=\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_k)
\end{split}
\end{split}\]</div>
<p>上式中，用到了<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭性，因此可以得知<span class="math notranslate nohighlight">\(\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}_k-\mathbf{x}_0)=0\)</span>。</p>
<p>  最终有，</p>
<div class="math notranslate nohighlight">
\[
\alpha_k=\frac{\mathbf{d}_k^\top\mathbf{A}(\mathbf{x}^*-\mathbf{x}_k)}{\mathbf{d}_k^\top\mathbf{Ad}_k}=\frac{\mathbf{d}_k^\top\mathbf{g}_k}{\mathbf{d}_k^\top\mathbf{Ad}_k}\tag{13}
\]</div>
</section>
<section id="id6">
<h3><span class="section-number">2.3.2. </span>共轭梯度法<a class="headerlink" href="#id6" title="永久链接至标题"></a></h3>
<p>  共轭梯度法是一种共轭方向方法。该方法选择的相继的方向向量被视为方法执行时相继获得的梯度的共轭版本。共轭方向并不是提前指定的，而是在每次序贯迭代时确定的。</p>
<p>  假设有<span class="math notranslate nohighlight">\(D=\{\mathbf{d}_1,...,\mathbf{d}_n\}\)</span>是<span class="math notranslate nohighlight">\(n\)</span>个<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭向量集，则函数<span class="math notranslate nohighlight">\(f(\mathbf{x}_0+\alpha_1\mathbf{d}_1+\cdots+\alpha_n\mathbf{d}_n)\)</span>的最小化可以从<span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>出发沿着<span class="math notranslate nohighlight">\(\mathbf{d}_1\)</span>的方向到达极小值点<span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span>，然后从<span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span>出发沿着<span class="math notranslate nohighlight">\(\mathbf{d}_2\)</span>的方向到达极小值点<span class="math notranslate nohighlight">\(\mathbf{x}_2\)</span>，如此继续就可以达到函数的最小值点。这种优化方法称之为共轭梯度法。</p>
<p>  上一节根据<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭已解决了<span class="math notranslate nohighlight">\(\alpha_i\)</span>的计算问题，剩下的工作就是要解决<span class="math notranslate nohighlight">\(\mathbf{d}_i\)</span>的计算问题。</p>
<p>  线性共轭梯度法一般使用以下规则来确定共轭方向<span class="math notranslate nohighlight">\(\mathbf{d}_{k+1}\)</span>，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{d}_{k+1}=\mathbf{g}_k+\beta_k\mathbf{d}_{k}\tag{14}
\]</div>
<p>即，下一个搜索方向是上一个搜索方向与负梯度的线性组合。那么，<span class="math notranslate nohighlight">\(\beta_k\)</span>怎么确定呢？</p>
<p>  显然，根据<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>-共轭性可知，<span class="math notranslate nohighlight">\(\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_{k+1}=0\)</span>，因此，对式(14)左右同时乘上<span class="math notranslate nohighlight">\(\mathbf{d}_k^\top\mathbf{A}\)</span>可得，</p>
<div class="math notranslate nohighlight">
\[
\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_{k+1}=\mathbf{d}_k^\top\mathbf{A}\mathbf{g}_{k}+\beta_k\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_{k}=0
\]</div>
<p>整理可得，</p>
<div class="math notranslate nohighlight">
\[
\beta_k=-\frac{\mathbf{d}_k^\top\mathbf{A}\mathbf{g}_{k}}{\mathbf{d}_k^\top\mathbf{A}\mathbf{d}_{k}}\tag{15}
\]</div>
<p>至此，线性共轭梯度算法的所有参数<span class="math notranslate nohighlight">\((\alpha_i,\beta_i)\)</span>已确定。</p>
<p>  对于二次凸函数，共轭梯度法的计算步骤如下：</p>
<ol class="arabic simple">
<li><p>给定初使点<span class="math notranslate nohighlight">\(\mathbf{x}_0,k=0\)</span></p></li>
<li><p>计算梯度<span class="math notranslate nohighlight">\(\mathbf{g}_k=-\nabla f(\mathbf{x}_k)\)</span>，若<span class="math notranslate nohighlight">\(\lVert\mathbf{g}_k\rVert=0\)</span>，则停止计算，否则下一步</p></li>
<li><p>构造搜索方向<span class="math notranslate nohighlight">\(\mathbf{d}_k=\mathbf{g}_k+\alpha_{k-1}\mathbf{d}_{k-1}\)</span></p></li>
<li><p>求下一个迭代点<span class="math notranslate nohighlight">\(\mathbf{x}_{k+1}=\mathbf{x}_k+\beta_k\mathbf{d}_k\)</span></p></li>
<li><p>若<span class="math notranslate nohighlight">\(k=n\)</span>，则停止计算，返回点<span class="math notranslate nohighlight">\(\mathbf{x}_k\)</span>,否则继续回到第2步。</p></li>
</ol>
</section>
<section id="id7">
<h3><span class="section-number">2.3.3. </span>案例<a class="headerlink" href="#id7" title="永久链接至标题"></a></h3>
<p>  <strong>例1</strong>. 考虑如下二次规划，</p>
<div class="math notranslate nohighlight">
\[
f(\mathbf{x})=\frac12\mathbf{x}^\top\mathbf{A}\mathbf{x}+\mathbf{b}^\top\mathbf{x}
\]</div>
<p>  其中，</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{A}=\left[\begin{array}{cc}\frac12&amp;\frac12\\\frac12&amp;1\end{array}\right],\quad\mathbf{b}=\left[\begin{array}{c}0\\2\end{array}\right]
\end{split}\]</div>
<p>求函数最小值，以及变量最优解<span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span><span class="o">+</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">linear_conj_desc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">A</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">epsilon</span><span class="p">):</span>
    <span class="n">g</span><span class="o">=</span><span class="n">b</span><span class="o">-</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">g</span> <span class="c1"># negative descent direction</span>
    
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">g</span><span class="p">)</span><span class="o">&lt;=</span><span class="n">epsilon</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">alpha</span><span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">g</span><span class="p">)</span><span class="o">/</span><span class="n">d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">alpha</span><span class="o">*</span><span class="n">d</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">b</span><span class="o">-</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="o">-</span><span class="n">d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">g</span><span class="p">))</span><span class="o">/</span><span class="n">d</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">g</span><span class="o">+</span><span class="n">beta</span><span class="o">*</span><span class="n">d</span>


<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">A</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">],[</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">b</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span><span class="mf">2.</span><span class="p">])</span>
    <span class="n">x_</span><span class="p">,</span><span class="n">f_</span><span class="o">=</span><span class="n">linear_conj_desc</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.3</span><span class="p">,</span><span class="o">-</span><span class="mf">2.2</span><span class="p">]),</span><span class="n">A</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="mi">10</span><span class="o">**-</span><span class="mi">5</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x=&quot;</span><span class="p">,</span><span class="n">x_</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">f_=&quot;</span><span class="p">,</span><span class="n">f_</span><span class="p">)</span>
</pre></div>
</div>
<p>  最后输出为，</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">4.</span>  <span class="mf">4.</span><span class="p">]</span>
<span class="n">f_</span><span class="o">=</span> <span class="o">-</span><span class="mf">1.7763568394002505e-15</span>
</pre></div>
</div>
</section>
<section id="id8">
<h3><span class="section-number">2.3.4. </span>一般函数的共轭梯度法<a class="headerlink" href="#id8" title="永久链接至标题"></a></h3>
<p>  一般函数的共轭梯度与二次函数梯度法的主要区别在于：步长<span class="math notranslate nohighlight">\(\alpha_i\)</span>不能再用原有方式计算须使用其它方法来确定；凡是用到矩阵<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>的地方都需要用当前迭代点的Hessian矩阵来替代。这样就可以将共轭梯度法扩展到一般函数。</p>
<p>  一般来说，使用这种方法来求任意函数的极小点，用有限步迭代是达不到的。迭代的方案可以有：直接延续使用原有共轭方向构造；或者<span class="math notranslate nohighlight">\(n\)</span>步作为一轮，每轮结束后取一次最速下降方向，开始下一轮。</p>
<p>  对于一般函数，共轭梯度法的计算步骤如下：</p>
<ol class="arabic simple">
<li><p>给定初使点<span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>，允许误差<span class="math notranslate nohighlight">\(\epsilon&gt;0\)</span>。</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\mathbf{y}_0=\mathbf{x}_0,\mathbf{d}_0=-\nabla f(\mathbf{y}_0),k=1,j=1
\]</div>
<ol class="arabic simple" start="2">
<li><p>若<span class="math notranslate nohighlight">\(\lVert\nabla f(\mathbf{y}_j)\rVert&lt;\epsilon\)</span>则停止计算。否则一维搜索，求<span class="math notranslate nohighlight">\(\alpha_j\)</span>满足下式，</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
f(\mathbf{y}_j+\alpha_j\mathbf{d}_j)=\min\limits_{\alpha\ge0}f(\mathbf{y}_j+\alpha\mathbf{d}_j)
\]</div>
<p>令</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y}_{j+1}=\mathbf{y}_j+\alpha_j\mathbf{d}_j
\]</div>
<ol class="arabic simple" start="3">
<li><p>如果<span class="math notranslate nohighlight">\(j&lt;n\)</span>，则进行步骤4；否则进行步骤5.</p></li>
<li><p>令<span class="math notranslate nohighlight">\(\mathbf{d}_{j+1}=-\nabla f(\mathbf{y}_{j+1})+\beta_j\mathbf{d}_j\)</span>，<span class="math notranslate nohighlight">\(j=j+1;\)</span>转步骤2。 其中，</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\beta_j=\frac{\lVert\nabla f(\mathbf{y}_{j+1})\rVert^2}{\lVert\nabla f(\mathbf{y}_{j})\rVert^2}
\]</div>
<ol class="arabic simple" start="5">
<li><p>令<span class="math notranslate nohighlight">\(\mathbf{x}_{k+1}=\mathbf{y}_{n+1},\mathbf{y}_0=\mathbf{x}_{k+1},\mathbf{d}_0=-\nabla f(\mathbf{y}_0),j=1,k=k+1\)</span>转步骤2.</p></li>
</ol>
</section>
</section>
<section id="id9">
<h2><span class="section-number">2.4. </span>Newton方法<a class="headerlink" href="#id9" title="永久链接至标题"></a></h2>
<ul>
<li><p><strong>Newton步径</strong>.  对于<span class="math notranslate nohighlight">\(x\in \mathbf{dom}f\)</span>，我们称向量</p>
<div class="math notranslate nohighlight">
\[
  \Delta \mathbf{x}_{nt}=-\nabla^2f(\mathbf{x})^{-1}\nabla f(\mathbf{x})
  \]</div>
<p>为<span class="math notranslate nohighlight">\(f\)</span>在<span class="math notranslate nohighlight">\(x\)</span>处的Newton步径。该步径是下降方向（除非<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>是最优点）。由<span class="math notranslate nohighlight">\(\nabla^2f( \mathbf{x})\)</span>的正定性可知，除非<span class="math notranslate nohighlight">\(\nabla f( \mathbf{x})=0\)</span>，否则就有，<span class="math notranslate nohighlight">\(\nabla f( \mathbf{x})^\top\Delta  \mathbf{x}_{nt}=-\nabla f( \mathbf{x})^\top\nabla^2f( \mathbf{x})^{-1}\nabla f( \mathbf{x})&lt;0\)</span>。</p>
</li>
</ul>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-left head"><p>Newton方法(阻尼Newton)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>1. 给定初使点<span class="math notranslate nohighlight">\(x\in\mathbf{dom}f\)</span>，误差阈值<span class="math notranslate nohighlight">\(\epsilon&gt;0。\)</span><br />2. 重复进行<br />  2.1 计算Newton步径和减量。<span class="math notranslate nohighlight">\(\Delta x_{nt}:=-\nabla^2 f(x)^{-1}\nabla f(x),\lambda^2:=\nabla f(x)^\top\nabla^2f(x)^{-1}\nabla f(x)\)</span>。<br />  2.2 停止准则。如果<span class="math notranslate nohighlight">\(\lambda^2/2\leq\epsilon\)</span>，退出。<br />  2.3 直线搜索。通过精确或回溯直线搜索确定步长<span class="math notranslate nohighlight">\(t\)</span>。<br />  2.4 修改。 <span class="math notranslate nohighlight">\(x:=x+t\Delta x_{nt}\)</span>。<br />直到满足停止准则。</p></td>
</tr>
</tbody>
</table>
<p>这实际上是通用下降方法，只是采用Newton步径为搜索方向。</p>
<ul class="simple">
<li><p><strong>Newton步的由来</strong>. 函数<span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span>在第<span class="math notranslate nohighlight">\(n\)</span>步点<span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span>处Taylor展开至第2阶近似，</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
  f(\mathbf{x})=f(\mathbf{x}_n)+\nabla f(\mathbf{x}_n)(\mathbf{x}-\mathbf{x}_n)+\frac{1}{2}\nabla^2 f(\mathbf{x}_n)(\mathbf{x}-\mathbf{x}_n)^2
  \]</div>
<p>使用<span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span>的最小点为新的探索点<span class="math notranslate nohighlight">\(\mathbf{x}_{n+1}\)</span>，因此，对式(67)左右同时求导，并令：</p>
<div class="math notranslate nohighlight">
\[
  \nabla f(\mathbf{x})=\nabla f(\mathbf{x}_n)+\nabla^2 f(\mathbf{x}_n)(\mathbf{x}-\mathbf{x}_n)=0
  \]</div>
<p>从而求得迭代公式：</p>
<div class="math notranslate nohighlight">
\[
  \mathbf{x}=\mathbf{x}_n-\nabla^2 f(\mathbf{x}_n)^{-1}\nabla f(\mathbf{x}_n)=\mathbf{x}_n+\Delta \mathbf{x}_{nt}
  \]</div>
<ul class="simple">
<li><p>Newton方法<strong>示例</strong></p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">a</span><span class="o">=</span><span class="mi">2</span>
<span class="n">b</span><span class="o">=</span><span class="mi">3</span>
<span class="n">c</span><span class="o">=</span><span class="mi">4</span>
<span class="n">d</span><span class="o">=</span><span class="mi">5</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">3</span><span class="o">+</span><span class="n">b</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">c</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">d</span>
<span class="k">def</span> <span class="nf">nablaf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">3</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">b</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">c</span>
<span class="k">def</span> <span class="nf">nabla2f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">3</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">b</span>
<span class="k">def</span> <span class="nf">newton</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span><span class="n">t</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">lambda2</span><span class="o">=</span><span class="n">nablaf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nabla2f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="mf">1e-4</span><span class="p">)</span><span class="o">*</span><span class="n">nablaf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">newton_step</span> <span class="o">=</span>  <span class="o">-</span><span class="mf">0.01</span><span class="o">*</span><span class="n">nablaf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nabla2f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="mf">1e-4</span><span class="p">)</span> <span class="c1">#alpha=0.01</span>
        <span class="k">if</span> <span class="n">lambda2</span><span class="o">/</span><span class="mi">2</span> <span class="o">&lt;=</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">newton_step</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x=(</span><span class="si">%10.2f</span><span class="s2">)</span><span class="se">\t</span><span class="s2">f(x)=(</span><span class="si">%10.2f</span><span class="se">\t</span><span class="s2">lambda2=(</span><span class="si">%10.2f</span><span class="s2">))&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">lambda2</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>   

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">x</span><span class="o">=</span><span class="mi">10000</span>
    <span class="n">y</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x=</span><span class="si">%10.2f</span><span class="s2">&quot;</span><span class="o">%</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>使用Newton方法求方程的解</p></li>
</ul>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="c1">//使用Newton方法求ax^3+bx^2+cx+d=0的解</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cmath&gt;</span><span class="cp"></span>

<span class="n">using</span><span class="w"> </span><span class="n">namespace</span><span class="w"> </span><span class="n">std</span><span class="p">;</span><span class="w"></span>
<span class="kt">double</span><span class="w"> </span><span class="nf">newton</span><span class="p">(</span><span class="kt">double</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="p">,</span><span class="kt">double</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="p">,</span><span class="kt">double</span><span class="p">);</span><span class="w"></span>

<span class="c1">//f(x)=a*x^3+b*x^2+c*x+d</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">double</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">d</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="o">=</span><span class="mf">10000.0</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="s">&quot;请输入4个系数：&quot;</span><span class="p">;</span><span class="w"> </span><span class="c1">//a=2,b=3,c=4,d=5</span>
<span class="w">	</span><span class="n">cin</span><span class="o">&gt;&gt;</span><span class="n">a</span><span class="o">&gt;&gt;</span><span class="n">b</span><span class="o">&gt;&gt;</span><span class="n">c</span><span class="o">&gt;&gt;</span><span class="n">d</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span>
<span class="w">	</span><span class="n">x</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="n">x</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="s">&quot;x=&quot;</span><span class="o">&lt;&lt;</span><span class="n">x</span><span class="o">&lt;&lt;</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="s">&quot;a^2=&quot;</span><span class="o">&lt;&lt;</span><span class="n">pow</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span><span class="w"></span>
<span class="w">	</span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">double</span><span class="w"> </span><span class="nf">newton</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="kt">double</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">d</span><span class="p">,</span><span class="kt">double</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">	</span><span class="kt">int</span><span class="w"> </span><span class="n">cnt</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">lambda2</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">){</span><span class="w">  </span><span class="c1">//abs(a*pow(x,3)+b*pow(x,2)+c*x+d)&gt;1e-5</span>
<span class="w">		</span><span class="n">lambda2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">b</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">c</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">6</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">b</span><span class="o">+</span><span class="mf">1e-4</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">b</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">c</span><span class="p">);</span><span class="w"></span>
<span class="w">		</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">0.01</span><span class="o">*</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">b</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">c</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">6</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">b</span><span class="o">+</span><span class="mf">1e-4</span><span class="p">);</span><span class="w"> </span><span class="c1">//学习率0.01可以继续优化。 </span>
<span class="w">		</span><span class="n">cnt</span><span class="o">++</span><span class="p">;</span><span class="w"></span>
<span class="w">		</span><span class="n">cout</span><span class="o">&lt;&lt;</span><span class="s">&quot;第&quot;</span><span class="o">&lt;&lt;</span><span class="n">cnt</span><span class="o">&lt;&lt;</span><span class="s">&quot;次迭代</span><span class="se">\t</span><span class="s">x=&quot;</span><span class="o">&lt;&lt;</span><span class="n">x</span><span class="o">&lt;&lt;</span><span class="s">&quot;</span><span class="se">\t</span><span class="s">函数f(x)=&quot;</span><span class="o">&lt;&lt;</span><span class="n">a</span><span class="o">*</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="o">*</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="n">c</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">d</span><span class="o">&lt;&lt;</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="w">		</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">lambda2</span><span class="o">/</span><span class="mi">2</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mf">1e-4</span><span class="p">)</span><span class="w"></span>
<span class="w">			</span><span class="k">break</span><span class="p">;</span><span class="w"></span>
<span class="w">	</span><span class="p">}</span><span class="w"></span>
<span class="w">	</span><span class="k">return</span><span class="w"> </span><span class="n">x</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="convex_prob.html" class="btn btn-neutral float-left" title="1. 凸优化问题" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="convex_neq_solve.html" class="btn btn-neutral float-right" title="3. 优化问题求解(2)" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2022, SSPUIIP.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>